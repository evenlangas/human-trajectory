{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4378d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c685880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x_0       0\n",
       "x_1       0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('dataCompressed12_5_100.csv')\n",
    "df = pd.read_csv('Data_Latest.csv')\n",
    "#df = pd.read_csv('dataCompressed3_125_100.csv')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc0c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367913</td>\n",
       "      <td>-0.073622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156383</td>\n",
       "      <td>0.192457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.159244</td>\n",
       "      <td>0.634766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.438949</td>\n",
       "      <td>1.160518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.859950</td>\n",
       "      <td>1.773462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_0       x_1  target\n",
       "0  0.367913 -0.073622       0\n",
       "1  0.156383  0.192457       0\n",
       "2 -0.159244  0.634766       0\n",
       "3 -0.438949  1.160518       0\n",
       "4 -0.859950  1.773462       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec26c618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_0', 'x_1', 'target'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.drop('series_id', axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb87421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_0', 'x_1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(df.columns)\n",
    "features.remove(\"target\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7642149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.290920</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285954</td>\n",
       "      <td>0.013256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.278544</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271977</td>\n",
       "      <td>0.060752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262093</td>\n",
       "      <td>0.090825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_0       x_1  target\n",
       "0  0.290920  0.000202       0\n",
       "1  0.285954  0.013256       0\n",
       "2  0.278544  0.034957       0\n",
       "3  0.271977  0.060752       0\n",
       "4  0.262093  0.090825       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724ce0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4570\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(0, len(data) - seq_length, round(seq_length/2)):\n",
    "        x = data[i:i+seq_length][['x_0', 'x_1']].values\n",
    "        y0 = data.iloc[i]['target']\n",
    "        y = data.iloc[i+seq_length]['target']\n",
    "        #xs.append(x)\n",
    "        #ys.append(y)\n",
    "        if y0 == y:\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "SEQ_LENGTH = 20\n",
    "#SEQ_LENGTH = 80\n",
    "x_data, y_data = create_sequences(df, SEQ_LENGTH)\n",
    "print(len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65f845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17918508 0.22762767]\n",
      " [0.16319321 0.26584239]\n",
      " [0.15388617 0.28502561]\n",
      " [0.14123338 0.29913535]\n",
      " [0.13500601 0.32221037]\n",
      " [0.13082129 0.34166325]\n",
      " [0.12644748 0.36063132]\n",
      " [0.11384828 0.3809321 ]\n",
      " [0.10002552 0.39102044]\n",
      " [0.08313302 0.408815  ]\n",
      " [0.07288624 0.42878543]\n",
      " [0.07085692 0.44680737]\n",
      " [0.06550267 0.47606836]\n",
      " [0.05921826 0.51276524]\n",
      " [0.05448514 0.55745678]\n",
      " [0.04900091 0.59917058]\n",
      " [0.05248728 0.63575895]\n",
      " [0.06473372 0.65698329]\n",
      " [0.07811452 0.6836644 ]\n",
      " [0.09100714 0.71022983]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699760c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb9a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder lists for the final training and test sets\n",
    "x_train_list, x_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "for label in df['target'].unique():\n",
    "    x_data_class, y_data_class = create_sequences(df[df['target'] == label], SEQ_LENGTH)\n",
    "    train_size = int(len(x_data_class) * 0.8)\n",
    "\n",
    "    # Split the data for this class\n",
    "    x_train_class, x_test_class = x_data_class[:train_size], x_data_class[train_size:]\n",
    "    y_train_class, y_test_class = y_data_class[:train_size], y_data_class[train_size:]\n",
    "\n",
    "    # Append to the final lists\n",
    "    x_train_list.append(x_train_class)\n",
    "    x_test_list.append(x_test_class)\n",
    "    y_train_list.append(y_train_class)\n",
    "    y_test_list.append(y_test_class)\n",
    "\n",
    "# Concatenate data from all classes to get the final training and test sets\n",
    "x_train = np.concatenate(x_train_list, axis=0)\n",
    "x_test = np.concatenate(x_test_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_test = np.concatenate(y_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79425588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0.0 in training data: 365 instances\n",
      "Label 1.0 in training data: 340 instances\n",
      "Label 2.0 in training data: 285 instances\n",
      "Label 3.0 in training data: 259 instances\n",
      "Label 4.0 in training data: 416 instances\n",
      "Label 5.0 in training data: 332 instances\n",
      "Label 6.0 in training data: 384 instances\n",
      "Label 7.0 in training data: 612 instances\n",
      "Label 8.0 in training data: 366 instances\n",
      "Label 9.0 in training data: 296 instances\n",
      "\n",
      "\n",
      "Label 0.0 in test data: 92 instances\n",
      "Label 1.0 in test data: 86 instances\n",
      "Label 2.0 in test data: 72 instances\n",
      "Label 3.0 in test data: 65 instances\n",
      "Label 4.0 in test data: 105 instances\n",
      "Label 5.0 in test data: 84 instances\n",
      "Label 6.0 in test data: 96 instances\n",
      "Label 7.0 in test data: 153 instances\n",
      "Label 8.0 in test data: 92 instances\n",
      "Label 9.0 in test data: 74 instances\n"
     ]
    }
   ],
   "source": [
    "# For training data\n",
    "unique_labels_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique_labels_train, counts_train):\n",
    "    print(f\"Label {label} in training data: {count} instances\")\n",
    "\n",
    "print(\"\\n\")  # Just to separate the outputs\n",
    "\n",
    "# For test data\n",
    "unique_labels_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "for label, count in zip(unique_labels_test, counts_test):\n",
    "    print(f\"Label {label} in test data: {count} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5881338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evenf\\anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dense, Flatten, Bidirectional\n",
    "\n",
    "metrics = [SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(300, activation='relu', return_sequences=True, input_shape=(SEQ_LENGTH, 2))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(200, activation='relu', return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(100, activation='relu', return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde86c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc1ce1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f8a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        units=hp.Int('units_1', min_value=200, max_value=500, step=50),\n",
    "        activation='relu',\n",
    "        return_sequences=True,\n",
    "        input_shape=(SEQ_LENGTH, 2)\n",
    "    )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        units=hp.Int('units_2', min_value=100, max_value=300, step=50),\n",
    "        activation='relu',\n",
    "        return_sequences=True\n",
    "    )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        units=hp.Int('units_3', min_value=50, max_value=200, step=50),\n",
    "        activation='relu'\n",
    "    )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('dense_units', min_value=100, max_value=300, step=50),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff49eeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # or however many trials you wish to run\n",
    "    #directory='C:\\\\Users\\\\evenf\\\\OneDrive - Universitetet i Agder\\\\Even and Hamza PhD project work\\\\Human trajectory simulations paper\\\\LSTM Model with Dataset\\\\keras_tuner_dir'\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=8, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a24c5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 23s 76ms/step - loss: 1.4177 - accuracy: 0.4389 - val_loss: 2.6036 - val_accuracy: 0.1643 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.9647 - accuracy: 0.6041 - val_loss: 2.5717 - val_accuracy: 0.1143 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.7445 - accuracy: 0.6848 - val_loss: 1.6075 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.6316 - accuracy: 0.7469 - val_loss: 0.6316 - val_accuracy: 0.7693 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.5356 - accuracy: 0.7770 - val_loss: 0.5684 - val_accuracy: 0.7301 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.4618 - accuracy: 0.8090 - val_loss: 0.3417 - val_accuracy: 0.8411 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.4403 - accuracy: 0.8172 - val_loss: 0.3716 - val_accuracy: 0.8607 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.4029 - accuracy: 0.8285 - val_loss: 0.4771 - val_accuracy: 0.8259 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.3782 - accuracy: 0.8424 - val_loss: 0.3006 - val_accuracy: 0.8629 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.3496 - accuracy: 0.8525 - val_loss: 0.2286 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.3792 - accuracy: 0.8449 - val_loss: 0.4561 - val_accuracy: 0.8107 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 18s 78ms/step - loss: 0.3189 - accuracy: 0.8648 - val_loss: 0.3992 - val_accuracy: 0.8313 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 18s 78ms/step - loss: 0.2965 - accuracy: 0.8662 - val_loss: 0.2125 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/100\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.3083 - accuracy: 0.8657 - val_loss: 0.2963 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.2834 - accuracy: 0.8832 - val_loss: 0.4831 - val_accuracy: 0.8074 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.8856\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.2721 - accuracy: 0.8856 - val_loss: 0.3416 - val_accuracy: 0.8662 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/100\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.2702 - accuracy: 0.8802 - val_loss: 0.3616 - val_accuracy: 0.8618 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.2463 - accuracy: 0.8903 - val_loss: 0.3641 - val_accuracy: 0.8487 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.2970 - accuracy: 0.8684 - val_loss: 0.1852 - val_accuracy: 0.9119 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/100\n",
      "229/229 [==============================] - 18s 76ms/step - loss: 0.2323 - accuracy: 0.9004 - val_loss: 0.2464 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 21/100\n",
      "229/229 [==============================] - 18s 77ms/step - loss: 0.2523 - accuracy: 0.8908 - val_loss: 0.2379 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 22/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9081\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.2078 - accuracy: 0.9081 - val_loss: 0.1912 - val_accuracy: 0.9151 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 23/100\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.2460 - accuracy: 0.8993 - val_loss: 0.2619 - val_accuracy: 0.8727 - lr: 0.0010\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 24/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.2391 - accuracy: 0.8958 - val_loss: 0.2842 - val_accuracy: 0.8705 - lr: 0.0010\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 25/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.8922\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.2442 - accuracy: 0.8922 - val_loss: 0.5910 - val_accuracy: 0.8400 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 26/100\n",
      "229/229 [==============================] - 16s 68ms/step - loss: 0.2358 - accuracy: 0.8955 - val_loss: 0.2362 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 27/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.2501 - accuracy: 0.8969 - val_loss: 0.2005 - val_accuracy: 0.9195 - lr: 0.0010\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 28/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9007\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 0.2369 - accuracy: 0.9007 - val_loss: 0.3010 - val_accuracy: 0.8629 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 29/100\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 0.2374 - accuracy: 0.9034 - val_loss: 0.4134 - val_accuracy: 0.8390 - lr: 0.0010\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 30/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.2658 - accuracy: 0.8845 - val_loss: 0.2516 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 31/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.8927\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.2488 - accuracy: 0.8927 - val_loss: 0.2697 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0009048374486155808.\n",
      "Epoch 32/100\n",
      "229/229 [==============================] - 16s 68ms/step - loss: 0.2208 - accuracy: 0.9067 - val_loss: 0.1984 - val_accuracy: 0.9129 - lr: 9.0484e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0008187307976186275.\n",
      "Epoch 33/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1793 - accuracy: 0.9190 - val_loss: 0.1619 - val_accuracy: 0.9282 - lr: 8.1873e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0007408182136714458.\n",
      "Epoch 34/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.2241 - accuracy: 0.8947 - val_loss: 0.1587 - val_accuracy: 0.9260 - lr: 7.4082e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0006703200633637607.\n",
      "Epoch 35/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1847 - accuracy: 0.9149 - val_loss: 0.1738 - val_accuracy: 0.9173 - lr: 6.7032e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0006065306952223182.\n",
      "Epoch 36/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.1820 - accuracy: 0.9196 - val_loss: 0.4019 - val_accuracy: 0.8183 - lr: 6.0653e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0005488116294145584.\n",
      "Epoch 37/100\n",
      "229/229 [==============================] - 18s 78ms/step - loss: 0.2042 - accuracy: 0.9116 - val_loss: 0.1396 - val_accuracy: 0.9347 - lr: 5.4881e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.000496585329528898.\n",
      "Epoch 38/100\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 0.1581 - accuracy: 0.9308 - val_loss: 0.1536 - val_accuracy: 0.9293 - lr: 4.9659e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0004493289743550122.\n",
      "Epoch 39/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.1693 - accuracy: 0.9259 - val_loss: 0.1744 - val_accuracy: 0.9260 - lr: 4.4933e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00040656968485563993.\n",
      "Epoch 40/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.9330\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 4.065696848556399e-06.\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1460 - accuracy: 0.9330 - val_loss: 0.1501 - val_accuracy: 0.9249 - lr: 4.0657e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.00036787946010008454.\n",
      "Epoch 41/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1445 - accuracy: 0.9368 - val_loss: 0.1744 - val_accuracy: 0.9293 - lr: 3.6788e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0003328711027279496.\n",
      "Epoch 42/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1489 - accuracy: 0.9272 - val_loss: 0.1363 - val_accuracy: 0.9358 - lr: 3.3287e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0003011942026205361.\n",
      "Epoch 43/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1423 - accuracy: 0.9346 - val_loss: 0.1192 - val_accuracy: 0.9456 - lr: 3.0119e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0002725318190641701.\n",
      "Epoch 44/100\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.1369 - accuracy: 0.9346 - val_loss: 0.1241 - val_accuracy: 0.9358 - lr: 2.7253e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0002465969882905483.\n",
      "Epoch 45/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.1255 - accuracy: 0.9420 - val_loss: 0.1868 - val_accuracy: 0.9293 - lr: 2.4660e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.00022313017689157277.\n",
      "Epoch 46/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9360\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 2.231301768915728e-06.\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.1342 - accuracy: 0.9360 - val_loss: 0.1245 - val_accuracy: 0.9423 - lr: 2.2313e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.00020189653150737286.\n",
      "Epoch 47/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1355 - accuracy: 0.9401 - val_loss: 0.1454 - val_accuracy: 0.9314 - lr: 2.0190e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00018268352141603827.\n",
      "Epoch 48/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1252 - accuracy: 0.9417 - val_loss: 0.1259 - val_accuracy: 0.9467 - lr: 1.8268e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00016529890126548707.\n",
      "Epoch 49/100\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.1230 - accuracy: 0.9439 - val_loss: 0.1149 - val_accuracy: 0.9478 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.000149568630149588.\n",
      "Epoch 50/100\n",
      "229/229 [==============================] - 18s 78ms/step - loss: 0.1240 - accuracy: 0.9428 - val_loss: 0.1214 - val_accuracy: 0.9499 - lr: 1.4957e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00013533528544940054.\n",
      "Epoch 51/100\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.1282 - accuracy: 0.9439 - val_loss: 0.1248 - val_accuracy: 0.9499 - lr: 1.3534e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00012245644757058471.\n",
      "Epoch 52/100\n",
      "229/229 [==============================] - 16s 72ms/step - loss: 0.1166 - accuracy: 0.9456 - val_loss: 0.1120 - val_accuracy: 0.9467 - lr: 1.2246e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.00011080315744038671.\n",
      "Epoch 53/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1184 - accuracy: 0.9447 - val_loss: 0.1212 - val_accuracy: 0.9412 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00010025885421782732.\n",
      "Epoch 54/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1133 - accuracy: 0.9475 - val_loss: 0.1183 - val_accuracy: 0.9467 - lr: 1.0026e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 9.071794920600951e-05.\n",
      "Epoch 55/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1206 - accuracy: 0.9415 - val_loss: 0.1063 - val_accuracy: 0.9456 - lr: 9.0718e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 8.208500366890803e-05.\n",
      "Epoch 56/100\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.1171 - accuracy: 0.9486 - val_loss: 0.1143 - val_accuracy: 0.9478 - lr: 8.2085e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 7.4273586506024e-05.\n",
      "Epoch 57/100\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.1141 - accuracy: 0.9497 - val_loss: 0.1219 - val_accuracy: 0.9499 - lr: 7.4274e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 6.720551755279303e-05.\n",
      "Epoch 58/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9469\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.720551755279302e-07.\n",
      "229/229 [==============================] - 18s 77ms/step - loss: 0.1136 - accuracy: 0.9469 - val_loss: 0.1172 - val_accuracy: 0.9499 - lr: 6.7206e-07\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 6.081007086322643e-05.\n",
      "Epoch 59/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.1105 - accuracy: 0.9510 - val_loss: 0.1228 - val_accuracy: 0.9456 - lr: 6.0810e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 5.50232180103194e-05.\n",
      "Epoch 60/100\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.1060 - accuracy: 0.9483 - val_loss: 0.1150 - val_accuracy: 0.9532 - lr: 5.5023e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 4.978706783731468e-05.\n",
      "Epoch 61/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9521\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 4.978706783731468e-07.\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1069 - accuracy: 0.9521 - val_loss: 0.1159 - val_accuracy: 0.9510 - lr: 4.9787e-07\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 4.504920798353851e-05.\n",
      "Epoch 62/100\n",
      "229/229 [==============================] - 16s 68ms/step - loss: 0.1082 - accuracy: 0.9494 - val_loss: 0.1165 - val_accuracy: 0.9554 - lr: 4.5049e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 4.076220284332521e-05.\n",
      "Epoch 63/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1084 - accuracy: 0.9505 - val_loss: 0.1219 - val_accuracy: 0.9510 - lr: 4.0762e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 3.6883167922496796e-05.\n",
      "Epoch 64/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9508\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.68831679224968e-07.\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1088 - accuracy: 0.9508 - val_loss: 0.1216 - val_accuracy: 0.9489 - lr: 3.6883e-07\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 3.3373267797287554e-05.\n",
      "Epoch 65/100\n",
      "229/229 [==============================] - 16s 72ms/step - loss: 0.1032 - accuracy: 0.9538 - val_loss: 0.1219 - val_accuracy: 0.9489 - lr: 3.3373e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 3.019738505827263e-05.\n",
      "Epoch 66/100\n",
      "229/229 [==============================] - 18s 77ms/step - loss: 0.1093 - accuracy: 0.9510 - val_loss: 0.1166 - val_accuracy: 0.9510 - lr: 3.0197e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 2.7323725589667447e-05.\n",
      "Epoch 67/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9494\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.7323725589667445e-07.\n",
      "229/229 [==============================] - 18s 76ms/step - loss: 0.1110 - accuracy: 0.9494 - val_loss: 0.1199 - val_accuracy: 0.9489 - lr: 2.7324e-07\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 2.4723527531023137e-05.\n",
      "Epoch 68/100\n",
      "229/229 [==============================] - 17s 72ms/step - loss: 0.1050 - accuracy: 0.9554 - val_loss: 0.1188 - val_accuracy: 0.9478 - lr: 2.4724e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 2.2370773876900785e-05.\n",
      "Epoch 69/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1039 - accuracy: 0.9502 - val_loss: 0.1180 - val_accuracy: 0.9489 - lr: 2.2371e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 2.0241910533513874e-05.\n",
      "Epoch 70/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9524\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 2.0241910533513874e-07.\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.0997 - accuracy: 0.9524 - val_loss: 0.1245 - val_accuracy: 0.9499 - lr: 2.0242e-07\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.831564077292569e-05.\n",
      "Epoch 71/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1051 - accuracy: 0.9529 - val_loss: 0.1194 - val_accuracy: 0.9521 - lr: 1.8316e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.6572677850490436e-05.\n",
      "Epoch 72/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1081 - accuracy: 0.9502 - val_loss: 0.1192 - val_accuracy: 0.9499 - lr: 1.6573e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.4995580386312213e-05.\n",
      "Epoch 73/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9518\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.4995580386312212e-07.\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.1040 - accuracy: 0.9518 - val_loss: 0.1169 - val_accuracy: 0.9543 - lr: 1.4996e-07\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.3568557733378839e-05.\n",
      "Epoch 74/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.1043 - accuracy: 0.9524 - val_loss: 0.1213 - val_accuracy: 0.9532 - lr: 1.3569e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.2277339010324795e-05.\n",
      "Epoch 75/100\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.1067 - accuracy: 0.9513 - val_loss: 0.1214 - val_accuracy: 0.9510 - lr: 1.2277e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.110899665945908e-05.\n",
      "Epoch 76/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9513\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.1108996659459081e-07.\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1035 - accuracy: 0.9513 - val_loss: 0.1209 - val_accuracy: 0.9489 - lr: 1.1109e-07\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.00518363979063e-05.\n",
      "Epoch 77/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.0964 - accuracy: 0.9570 - val_loss: 0.1223 - val_accuracy: 0.9554 - lr: 1.0052e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 9.09527898329543e-06.\n",
      "Epoch 78/100\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.0993 - accuracy: 0.9557 - val_loss: 0.1218 - val_accuracy: 0.9543 - lr: 9.0953e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 8.229745617427398e-06.\n",
      "Epoch 79/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9524\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 8.229745617427397e-08.\n",
      "229/229 [==============================] - 18s 79ms/step - loss: 0.1029 - accuracy: 0.9524 - val_loss: 0.1214 - val_accuracy: 0.9532 - lr: 8.2297e-08\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 7.446582912962185e-06.\n",
      "Epoch 80/100\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.1006 - accuracy: 0.9508 - val_loss: 0.1214 - val_accuracy: 0.9532 - lr: 7.4466e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 6.737947387591703e-06.\n",
      "Epoch 81/100\n",
      "229/229 [==============================] - 16s 72ms/step - loss: 0.1020 - accuracy: 0.9516 - val_loss: 0.1221 - val_accuracy: 0.9489 - lr: 6.7379e-06\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 6.096747711126227e-06.\n",
      "Epoch 82/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9516\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.096747711126227e-08.\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.1046 - accuracy: 0.9516 - val_loss: 0.1213 - val_accuracy: 0.9510 - lr: 6.0967e-08\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 5.516565579455346e-06.\n",
      "Epoch 83/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1020 - accuracy: 0.9549 - val_loss: 0.1221 - val_accuracy: 0.9510 - lr: 5.5166e-06\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 4.991592959413538e-06.\n",
      "Epoch 84/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.1004 - accuracy: 0.9535 - val_loss: 0.1191 - val_accuracy: 0.9499 - lr: 4.9916e-06\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 4.51658070232952e-06.\n",
      "Epoch 85/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9521\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.51658070232952e-08.\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1011 - accuracy: 0.9521 - val_loss: 0.1195 - val_accuracy: 0.9521 - lr: 4.5166e-08\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 4.08677169616567e-06.\n",
      "Epoch 86/100\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.0980 - accuracy: 0.9527 - val_loss: 0.1196 - val_accuracy: 0.9499 - lr: 4.0868e-06\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 3.697864258356276e-06.\n",
      "Epoch 87/100\n",
      "229/229 [==============================] - 17s 72ms/step - loss: 0.0994 - accuracy: 0.9557 - val_loss: 0.1193 - val_accuracy: 0.9510 - lr: 3.6979e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 3.3459662063251017e-06.\n",
      "Epoch 88/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9546\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.3459662063251015e-08.\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1019 - accuracy: 0.9546 - val_loss: 0.1203 - val_accuracy: 0.9521 - lr: 3.3460e-08\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 3.027554384971154e-06.\n",
      "Epoch 89/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.0967 - accuracy: 0.9562 - val_loss: 0.1205 - val_accuracy: 0.9521 - lr: 3.0276e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 2.7394446533435257e-06.\n",
      "Epoch 90/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1022 - accuracy: 0.9527 - val_loss: 0.1208 - val_accuracy: 0.9521 - lr: 2.7394e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 2.4787523216218688e-06.\n",
      "Epoch 91/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9521\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.478752321621869e-08.\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.0995 - accuracy: 0.9521 - val_loss: 0.1209 - val_accuracy: 0.9510 - lr: 2.4788e-08\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 2.2428680495067965e-06.\n",
      "Epoch 92/100\n",
      "229/229 [==============================] - 18s 79ms/step - loss: 0.0969 - accuracy: 0.9546 - val_loss: 0.1217 - val_accuracy: 0.9510 - lr: 2.2429e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 2.0294312434998574e-06.\n",
      "Epoch 93/100\n",
      "229/229 [==============================] - 17s 74ms/step - loss: 0.1031 - accuracy: 0.9560 - val_loss: 0.1211 - val_accuracy: 0.9499 - lr: 2.0294e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.8363044773650472e-06.\n",
      "Epoch 94/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9497\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.8363044773650474e-08.\n",
      "229/229 [==============================] - 16s 72ms/step - loss: 0.1063 - accuracy: 0.9497 - val_loss: 0.1215 - val_accuracy: 0.9510 - lr: 1.8363e-08\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.6615572349110153e-06.\n",
      "Epoch 95/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.0972 - accuracy: 0.9573 - val_loss: 0.1216 - val_accuracy: 0.9521 - lr: 1.6616e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 1.5034391935841995e-06.\n",
      "Epoch 96/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.1003 - accuracy: 0.9565 - val_loss: 0.1221 - val_accuracy: 0.9521 - lr: 1.5034e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 1.360368287350866e-06.\n",
      "Epoch 97/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9573\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.3603682873508661e-08.\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.0957 - accuracy: 0.9573 - val_loss: 0.1212 - val_accuracy: 0.9521 - lr: 1.3604e-08\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 1.23091217574256e-06.\n",
      "Epoch 98/100\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.0981 - accuracy: 0.9557 - val_loss: 0.1212 - val_accuracy: 0.9532 - lr: 1.2309e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.1137750561829307e-06.\n",
      "Epoch 99/100\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 0.1005 - accuracy: 0.9532 - val_loss: 0.1209 - val_accuracy: 0.9521 - lr: 1.1138e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.0077853858092567e-06.\n",
      "Epoch 100/100\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9535\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.0077853858092568e-08.\n",
      "229/229 [==============================] - 18s 78ms/step - loss: 0.1017 - accuracy: 0.9535 - val_loss: 0.1221 - val_accuracy: 0.9510 - lr: 1.0078e-08\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "csv_logger = CSVLogger('logs.csv', separator = ',', append = True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3, verbose=1)\n",
    "def custom_lr_schedule(epoch):\n",
    "    if epoch < 30:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (30 - epoch))\n",
    "lr_scheduler = LearningRateScheduler(custom_lr_schedule, verbose=1)\n",
    "lstm_history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), batch_size=16, callbacks=[reduce_lr, lr_scheduler, csv_logger])\n",
    "\n",
    "model.save('model_bilstm.keras')\n",
    "np.save('history_bilstm.npy',lstm_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d41864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 22ms/step\n",
      "(20, 2)\n",
      "(919, 10)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 4 1 1 1 1 1 1 1 1 7 1 1 1 1 1 1 1 7 1\n",
      " 1 1 1 7 1 1 1 1 1 1 1 4 1 1 1 4 1 1 1 1 1 1 1 1 7 1 1 1 7 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 8 2 2 2 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 1 4 4 4 4 7 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4\n",
      " 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 1 4 4 4 4 4 4 4 4 4 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6 7 6 6 6 6 7 7 6 6 6 7 6\n",
      " 6 6 6 7 6 6 6 6 6 6 6 6 7 6 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 5 6 7 7 7 7 7 7 6 7 7 7 7 7 7 7 6 7 7 7 7 4 7 7 7 7 7 7 7 7 7 6 6 7 7\n",
      " 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 4 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 4 7 7\n",
      " 6 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "classes_x=np.argmax(predictions,axis=1)\n",
    "\n",
    "print(x_test[1].shape)\n",
    "print(predictions.shape)\n",
    "print(classes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "548b1bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 90,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,  76,   0,   0,   5,   0,   0,   5,   0,   0],\n",
       "       [  0,   0,  70,   0,   0,   0,   0,   0,   2,   0],\n",
       "       [  0,   0,   0,  65,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   6,   0,   0,  98,   0,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  83,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,  88,   6,   0,   0],\n",
       "       [  0,   0,   0,   0,   3,   1,  11, 138,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  92,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  74]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=classes_x, num_classes=10)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2f3fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "font_style = {'family' : 'sans-serif', # 'Times New Roman'\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "font_style_nr = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "hm = sns.heatmap(cm, annot=True, cmap='Blues',fmt='g', annot_kws={'fontdict': font_style_nr})\n",
    "hm.set_xticklabels(hm.get_xticklabels(), fontdict=font_style_nr)\n",
    "hm.set_yticklabels(hm.get_yticklabels(), fontdict=font_style_nr)\n",
    "cbar = hm.collections[0].colorbar\n",
    "# Set font style for colorbar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontsize(12)\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontweight('normal')\n",
    "\n",
    "plt.xlabel('Predicted Labels', fontdict=font_style)\n",
    "plt.ylabel('True Labels', fontdict=font_style)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb060fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        92\n",
      "         1.0       0.90      0.88      0.89        86\n",
      "         2.0       1.00      0.97      0.99        72\n",
      "         3.0       1.00      1.00      1.00        65\n",
      "         4.0       0.92      0.93      0.93       105\n",
      "         5.0       0.97      0.99      0.98        84\n",
      "         6.0       0.88      0.92      0.90        96\n",
      "         7.0       0.92      0.90      0.91       153\n",
      "         8.0       0.98      1.00      0.99        92\n",
      "         9.0       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           0.95       919\n",
      "   macro avg       0.96      0.96      0.96       919\n",
      "weighted avg       0.95      0.95      0.95       919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, classes_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
